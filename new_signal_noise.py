import json
import os
import random
import numpy as np
import pyroomacoustics as pa
import soundfile as sf
from tqdm import tqdm
from pathlib import Path
import sys

# my_moduleãŒæä¾›ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¾ã™
from mymodule import const, rec_config as rec_conf, rec_utility as rec_util
from mymodule import my_func, reverbe_feater as rev_feat


def create_reverb_dataset_final(
		target_dir: Path,
		noise_path: Path,
		output_dir: Path,
		num_rooms: int,
		num_files_per_room: int,
		snr: float,
		channel: int = 1
):
	"""
	è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°ã€‚
	- è¤‡æ•°ã®ã€Œéƒ¨å±‹ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰ã€ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã€‚
	- å„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³IDã€ç‰©ç†çš„ç‰¹å¾´é‡ï¼‰ã‚’ä¿å­˜ã™ã‚‹ã€‚
	- ç›®çš„ä¿¡å·ã¨é›‘éŸ³ä¿¡å·ã®ä¸¡æ–¹ã«å€‹åˆ¥ã«æ®‹éŸ¿ã‚’ä»˜åŠ ã—ã€çµåˆã™ã‚‹ã€‚
	"""
	output_dir.mkdir(parents=True, exist_ok=True)
	metadata_path = output_dir / "metadata.json"
	metadata = {}

	# ç›®çš„ä¿¡å·ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—
	speech_files = list(target_dir.rglob("*.wav"))
	if not speech_files:
		print(f"âŒ ã‚¨ãƒ©ãƒ¼: ç›®çš„ä¿¡å·ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_dir}", file=sys.stderr)
		return

	print(f"âœ… ç›®çš„ä¿¡å·ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®å–å¾—å®Œäº†ã€‚{len(speech_files)} å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã™ã€‚")

	# é›‘éŸ³ä¿¡å·ã®èª­ã¿è¾¼ã¿ (ä¸€åº¦ã ã‘)
	try:
		noise_signal_orig, fs_noise = sf.read(noise_path)
	except FileNotFoundError:
		print(f"âŒ ã‚¨ãƒ©ãƒ¼: é›‘éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {noise_path}", file=sys.stderr)
		return

	if noise_signal_orig.ndim > 1:
		noise_signal_orig = noise_signal_orig.mean(axis=1)

	# éƒ¨å±‹ã”ã¨ã«ãƒ«ãƒ¼ãƒ—
	for room_id in range(num_rooms):
		print(f"\n--- Simulating Room (Domain) ID: {room_id} ---")

		# ãƒ©ãƒ³ãƒ€ãƒ ãªéƒ¨å±‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ (ã‚µã‚¤ã‚ºã¨å¸éŸ³ç‡ã¯é©å®œèª¿æ•´ã—ã¦ãã ã•ã„)
		room_dim = np.array([random.uniform(3, 8), random.uniform(3, 8), random.uniform(2.5, 4)])
		# Sabineã®æ®‹éŸ¿å¼ã‹ã‚‰å¸åç‡ã¨åå°„ä¸Šé™å›æ•°ã‚’æ±ºå®š
		rt60_target = random.uniform(0.1, 1.0)
		e_absorption, max_order = pa.inverse_sabine(rt60_target, room_dim)

		# éƒ¨å±‹ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«æƒ…å ±ã‚’è¨˜éŒ²
		room_metadata = {
			"room_id": room_id,
			"room_dim": room_dim.tolist(),
			"target_rt60": rt60_target,
			"absorption": e_absorption,
			"max_order": max_order,
			"files": []
		}

		# éƒ¨å±‹ã®ä½œæˆã¨ãƒã‚¤ã‚¯ã®è¨­ç½®
		room = pa.ShoeBox(room_dim, fs=rec_conf.sampling_rate, max_order=max_order, materials=pa.Material(e_absorption))
		mic_center = room_dim / 2
		mic_coordinate = rec_util.set_mic_coordinate(center=mic_center, num_channels=channel, distance=0.1)
		room.add_microphone_array(pa.MicrophoneArray(mic_coordinate, fs=room.fs))

		# éŸ³æºã®ä½ç½®ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«è¨­å®šï¼ˆå£ã‹ã‚‰é›¢ã™ï¼‰
		source_pos_signal = np.array([
			random.uniform(0.5, room_dim[0] - 0.5),
			random.uniform(0.5, room_dim[1] - 0.5),
			random.uniform(0.5, room_dim[2] - 0.5)
		])
		source_pos_noise = np.array([
			random.uniform(0.5, room_dim[0] - 0.5),
			random.uniform(0.5, room_dim[1] - 0.5),
			random.uniform(0.5, room_dim[2] - 0.5)
		])

		# éŸ³æºã®è¿½åŠ 
		room.add_source(source_pos_signal)
		room.add_source(source_pos_noise)

		# RIRã‚’è¨ˆç®—
		room.compute_rir()
		rir_signal = room.rir[0][0]  # ç›®çš„ä¿¡å·ã®RIR
		rir_noise = room.rir[0][1]  # é›‘éŸ³ä¿¡å·ã®RIR

		# ç‰©ç†çš„ç‰¹å¾´é‡ï¼ˆRT60, C50, D50ï¼‰ã‚’è¨ˆç®—
		# rirãŒ2æ¬¡å…ƒé…åˆ—ï¼ˆãƒã‚¤ã‚¯, ã‚½ãƒ¼ã‚¹ï¼‰ã§è¿”ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€æœ€åˆã®RIRã‚’ä½¿ç”¨
		rt60 = room.measure_rt60()[0][0]
		c50 = rev_feat.calculate_c50(rir_signal)
		d50 = rev_feat.calculate_d50(rir_signal)

		# å„éƒ¨å±‹ã§æŒ‡å®šã•ã‚ŒãŸæ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
		selected_speech_files = random.sample(speech_files, k=num_files_per_room)
		for clean_filepath in tqdm(selected_speech_files, desc=f"Generating files for room {room_id}"):
			try:
				# ã‚¯ãƒªãƒ¼ãƒ³éŸ³å£°ä¿¡å·ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
				clean_signal, fs_clean = sf.read(clean_filepath)
				if clean_signal.ndim > 1:
					clean_signal = clean_signal.mean(axis=1)

				# é›‘éŸ³ä¿¡å·ã‚’åˆ‡ã‚Šå‡ºã—
				start_noise = random.randint(0, len(noise_signal_orig) - len(clean_signal))
				noise_segment_orig = noise_signal_orig[start_noise: start_noise + len(clean_signal)]

				# RIRã§ç•³ã¿è¾¼ã¿ã€æ®‹éŸ¿ä»˜ãä¿¡å·ã‚’ç”Ÿæˆ
				reverb_signal = np.convolve(clean_signal, rir_signal, mode='full')[:len(clean_signal)]
				reverb_noise = np.convolve(noise_segment_orig, rir_noise, mode='full')[:len(noise_segment_orig)]

				# SNRã‚’èª¿æ•´ã—ã¦çµåˆ
				scaled_noise = rec_util.get_scale_noise(reverb_signal, reverb_noise, snr)
				mixed_signal = reverb_signal + scaled_noise

				# ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
				base_filename = clean_filepath.stem
				output_filename = f"{base_filename}_room{room_id:03}_rt{int(rt60 * 10):03}_snr{snr:02}.wav"

				# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
				output_sub_dir = output_dir / f"room_{room_id}"
				output_sub_dir.mkdir(parents=True, exist_ok=True)

				output_path = output_sub_dir / output_filename
				sf.write(output_path, mixed_signal, rec_conf.sampling_rate)

				# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¿½åŠ 
				file_metadata = {
					"filename": output_filename,
					"clean_source_file": clean_filepath.name,
					"rt60": rt60,
					"c50": c50,
					"d50": d50,
					"snr": snr
				}
				room_metadata["files"].append(file_metadata)

			except Exception as e:
				tqdm.write(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {clean_filepath.name} ({e})", file=sys.stderr)

		metadata[f"room_{room_id}"] = room_metadata

	# å…¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
	with open(metadata_path, "w") as f:
		json.dump(metadata, f, indent=4)

	print("\nğŸ‰ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
	# ä½¿ç”¨ä¾‹
	speech_type = "subset_DEMAND"
	noise_type = "hoth"

	# `mymodule/const.py`ã«å®šç¾©ã•ã‚ŒãŸãƒ‘ã‚¹ã‚’åŸºã«è¨­å®š
	try:
		sample_data_dir = Path(const.SAMPLE_DATA_DIR)
		mix_data_dir = Path(const.MIX_DATA_DIR)
	except NameError:
		print("const.pyã®ãƒ‘ã‚¹è¨­å®šãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚æ‰‹å‹•ã§ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚")
		sample_data_dir = Path("./sound_data/sample_data")
		mix_data_dir = Path("./sound_data/mix_data")

	# `train/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
	data_type = "test"
	target_dir = sample_data_dir / "speech" / speech_type / data_type
	# `noise/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®é›‘éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
	noise_path = sample_data_dir / "noise" / f"{noise_type}.wav"
	output_dir = mix_data_dir / "reverb_encoder_dataset" / data_type

	create_reverb_dataset_final(
		target_dir=target_dir,
		noise_path=noise_path,
		output_dir=output_dir,
		num_rooms=10,
		num_files_per_room=20,
		snr=10,
		channel=1
	)